CS231n 3주차
============

**1. Today..**
-----
--------------------------

   - Loss function
   - Regularization
   - Optimization


**2. 강의 요약**
-----
------------------

**1)  Loss function**

* Loss fuction이란?
  : 입력 받은 weight가 정답과 얼마나 차이가 나는지 정량적으로 측정

◾ 종류
- Multiclass SVM
각 class별 점수를 계산하고, 그 점수와 제대로 분류된 label의 score 간의 차이를 계산하는 함수

![SVM form](https://user-images.githubusercontent.com/66044830/112720883-4732ed00-8f44-11eb-819f-35cb47486071.JPG)
이 loss function을 **Hinge loss**라고 부른다.

(여기서 **$s_j = $ 잘못 분류된 score** , **$s_{yi} = $ class의 정답 label의 score**이다. 
$+1$은 safety margin으로 predict와 true값에 상대적인 차이를 주기 위한 설정이다.)

![hinge loss](https://user-images.githubusercontent.com/66044830/112721132-9af20600-8f45-11eb-9d2d-6e7ceb345103.JPG)

Hinge loss, 즉 Multiclass SVM loss의 minimum 값은 0이며, maximum 값은 무한대이다.

강의자료에 언급된 Question에 대해 정리하자면,
> * Q1 : What happens to loss if car scores change a bit?
> * Q2 : (min/max 값 -> 바로 위에서 답변)
> * Q3 : At initialization W is small so all s ~= 0. What is the loss
> * Q4 : What if the sum was over all classes?(including $j={yi}$)
> * Q5 : What if we used mean instead of sum?
> * Q6 : 손실함수를 ${max{(0,s_j - s_{yi} +1)^2}}$로 바꾸면?

의 질문이 있었다. 하나씩 답을 해보자면,
> * A1 : car score가 변하더라도 class간의 상대적인 차이가 중요하기 때문에 큰 영향은 끼치지 않는다.
> * A3 : mean = 2가 될 것이며 일반화 하면 ${(class의 개수 - 1)}$이 된다. 이 때의 loss값을 이용하여 최초의 학습을 시켰을 때 제대로 실행된 것이 맞는지 확인해볼 수 있다.
> * A4 : 같은 값을 빼고 더한 뒤 +1을 해주기 때문에 모든 값들이 1씩 증가한다. 결과적으로 평균도 +1된다.
> * A5 : class 별 비교이기 때문에 의미 없음ㅎㅅㅎ
> * A6 : 손실함수 자체가 달라지는 것이기 때문에 결과도 달라질 수 있다.

❓ L = 0인 W(weight)값은 unique한가?
The answer is.. **NO**! 그래서 train data로 학습을 시키면서 W를 찾고, test 시켰을 때 가장 성능이 좋은 것을 choose하면 된다.

--------------------------------------
**2) Regularization**
: Unique한 weight값을 결정하고 model complexity에 패널티를 부여함으로써 training set이 overfiting되는 것을 방지함.

![정규화](https://user-images.githubusercontent.com/66044830/112722305-1b1b6a00-8f4c-11eb-87f8-ae02c534cf25.JPG)

     data loss와 Regularization 사이에 trading off가 일어남

* Regularization EX
1 ) Ll regularization
2 ) L2 regularization
3 ) Elastic net
4 ) Dropout
5 ) Batch normalization
...etc

* Regularization이 필요한 이유
  - Express preferences over weights
  - Make the model simple so it works on test data
  - Improve optimization by adding curature


✔ Softmax (Multinomial Logistic Regression)
: 잘분류 된 것과 잘못 분류된 것의 차이를 모두 수치화하여(확률계산) 보여줌

![softmax](https://user-images.githubusercontent.com/66044830/112741815-c1ef1d00-8fc3-11eb-825e-e11c51918ffa.png)

위의 식이 softmax function이고 이 함수를 이용하여 loss값인 cross-entropy loss를 구한다.

$L_i = -logP{(Y = y_i | X = x_i)} = - log{(\frac{e^{sy_i}}{\sum_{j}e^s_j})}$ **: Cross-entropy loss**

> 제대로 분류된 class의 probability를 maximize시키기 위해 -를 붙였고, 수가 너무 커지는 것을 방지하고 더 nice한 distribution을 얻기위해 log를 취했다.

그렇다면 이런 loss function과 정규화를 통해 어떻게 최적의 W를 구할 수 있는걸까? 

---------------------------
**3)** **Optimization**

* (bad idea) Random search
```python
for num in xrange(1000) :
  W = np.random.randn(10,3073) * 0.0001
  loss = L(X_train, Y_train, W)

  if loss < bestloss :
    best loss update
```
이렇게 정말 랜!덤!으로 하면 accuracy가 0.15~ 0.95까지 널뛰기를 한다.. 그래서 minimize할 수 있는 방향성을 갖고 opitmization하는 방법을 찾음.

* Analytic gradient : 미분을 통해서 점점 minimum값을 찾아가는 접근 방법
  
  - numerical gradient보다 정확하지만 코드 작성에 어려움이 있다. Numerical gradient는 간단하지만 느리다는 단점이 있다. 그래서 checking용으로 쓰인다.

* Gradient Descent Algorithm
```python
while True :
  weights_grad = evaluate_gradient(loss_fun, data, weights)
  weights += - step_size(= learning rate = alhpa) * weights_grad
  ```

* Stochastic Gradient Descent(SGD)
  - 모든 데이터를 Gradient descent를 이용해서 계산하기에는 많은 시간이 소요되기 때문에 minibatch를 이용한다.(쉽게 말하자면 데이터 묶음 정도)

```python
while True :
  data_batch = sample_training_data(data, 256) # 128/256/512..etc
  weights_grad = evaluate_gradient(loss_fun, data, weights)
  weights += - step_size(= learning rate = alhpa) * weights_grad
  ```
추가적으로 weights를 update 시키는 방법에 따라 momentum / Adam 등의 방법이 존재한다.

---------------------------
➕

  ![3_image feature](https://user-images.githubusercontent.com/66044830/112742378-08934600-8fc9-11eb-857c-3bf67be17662.png)

* Image feature
  - Color Histogram
  - HOG (Histogram of Oriented Gradients)
  
등의 방법으로 feature Extraction을 한다.

이전의 Feature Extraction을 하는 방법에서 벗어나 더이상 인간이 Feature들을 추출하지 않는 것으로 바뀌었다.
